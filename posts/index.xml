<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Hi, I&#39;m Abhijit Pai.</title>
		<link>https://abhijitpai000.github.io/posts/</link>
		<description>Recent content in Posts on Hi, I&#39;m Abhijit Pai.</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Tue, 08 Dec 2020 00:00:00 +0000</lastBuildDate>
		<atom:link href="https://abhijitpai000.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Moviebot Mike</title>
			<link>https://abhijitpai000.github.io/posts/moviebot-mike/</link>
			<pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
			
			<guid>https://abhijitpai000.github.io/posts/moviebot-mike/</guid>
			<description>Features Mike predicts 9 user intents, makes recommendations for about 200 IMDb 7+ rated Bollywood movies from the 2010 - 2019 era based on plot similarity, gives movie plots, and drops movie dialogues in the conversation.
Related Links  Web app link (Heroku) Web app repo (Github) Model Training repo (Github)  NOTE: The web app is deployed on a free server which goes into sleep mode and takes about 10s for boot up, once loaded the bot will work as expected.</description>
			<content type="html"><![CDATA[<h2 id="features">Features</h2>
<p>Mike predicts 9 user intents, makes recommendations for about 200 IMDb 7+ rated Bollywood movies from the 2010 - 2019 era based on plot similarity, gives movie plots, and drops movie dialogues in the conversation.</p>
<p><img src="/moviebot-mike-demo2.JPG" alt="Demo 2"></p>
<h2 id="related-links">Related Links</h2>
<ul>
<li><a href="https://moviebot-mike.herokuapp.com/"><strong>Web app link (Heroku)</strong></a></li>
<li><a href="https://github.com/abhijitpai000/moviebot-mike"><strong>Web app repo (Github)</strong></a></li>
<li><a href="https://github.com/abhijitpai000/moviebot-mike-training"><strong>Model Training repo (Github)</strong></a></li>
</ul>
<p><em><strong>NOTE:</strong> The web app is deployed on a free server which goes into sleep mode and takes about 10s for boot up, once loaded the bot will work as expected.</em></p>
<h2 id="data-source">Data Source</h2>
<p>I&rsquo;m using <a href="https://www.kaggle.com/pncnmnp/the-indian-movie-database?select=2010-2019">The Indian Movie Database</a> dataset from Kaggle for the Movie Recommendation part of the project.</p>
<h2 id="usage-guide">Usage Guide</h2>
<p><em>When a user asks for a recommendation, the bot activates the a module that handles such requests, following are commands to trigger that module</em></p>
<ul>
<li>For Movie Recommendations enter <em>&ldquo;movies like movie-title&rdquo;</em> command.
<pre><code>&gt;&gt; movies like rockstar
</code></pre></li>
<li>For Movie Plots enter <em>&ldquo;about movie-title&rdquo;</em> command.
<pre><code>&gt;&gt; about zindagi na milegi dobara
</code></pre></li>
<li>Easter Eggs.
<pre><code>&gt;&gt; who are you?
&gt;&gt; what did you do all day?
</code></pre></li>
<li>Casual conversation.
<pre><code>&gt;&gt; how are you?
&gt;&gt; do you have friends?
&gt;&gt; you're mean
</code></pre></li>
</ul>
<h2 id="architecture">Architecture</h2>
<p><img src="/moviebot-mike.JPG" alt="This is an image"></p>
<h2 id="extended-features">Extended Features</h2>
<table>
<thead>
<tr>
<th style="text-align:left">Feature     </th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Unk Handler</strong></td>
<td style="text-align:left">Implemented a module to replace out of vocabulary words (words not seen in training) detected in a user request with &lsquo;unk&rsquo; to gain maximum information out of the request, the UNK percent in the bot response refers to that.</td>
</tr>
<tr>
<td style="text-align:left"><strong>Movie Title Spellings</strong></td>
<td style="text-align:left">To handle variations of movie title spelling, implemented a module that computes Levenstein distance between user input movie title and the ones in the database to capture appropriate movie title given by the user.</td>
</tr>
<tr>
<td style="text-align:left"><strong>Profanity Handler</strong></td>
<td style="text-align:left">Implemented an intent that tries to detect swear words in a user&rsquo;s request.</td>
</tr>
</tbody>
</table>
]]></content>
		</item>
		
		<item>
			<title>Product RecSys</title>
			<link>https://abhijitpai000.github.io/posts/product-recsys/</link>
			<pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
			
			<guid>https://abhijitpai000.github.io/posts/product-recsys/</guid>
			<description>About Using the customer orders and rating data from Olist E-Commerce Public Dataset, which has information about 100k orders made at multiple marketplaces in Brazil from 2016 to 2018, I trained 3 models that generate product recommendations.
NOTE - The granularity of orders in the dataset is at the product category level, thus recommendations are product categories in the true sense.
Related Links  Web app link (Heroku). Web app (Github) Model Training (Github)  NOTE: The web app is deployed on a free server which goes into sleep mode and takes about 10s for boot up, once loaded the bot will work as expected.</description>
			<content type="html"><![CDATA[<h2 id="about">About</h2>
<p>Using the customer orders and rating data from <a href="https://www.kaggle.com/olistbr/brazilian-ecommerce">Olist E-Commerce Public Dataset</a>, which has information about 100k orders made at multiple marketplaces in Brazil from 2016 to 2018, I trained 3 models that generate product recommendations.</p>
<p><em>NOTE</em> 
<em>- The granularity of orders in the dataset is at the product category level, thus recommendations are product categories in the true sense.</em></p>
<p><img src="/product-recsys-demo.gif" alt="Demo 2"></p>
<h2 id="related-links">Related Links</h2>
<ul>
<li><a href="http://product-recsys.herokuapp.com/"><strong>Web app link (Heroku)</strong></a>.</li>
<li><a href="https://github.com/abhijitpai000/product-recsys"><strong>Web app (Github)</strong></a></li>
<li><a href="https://github.com/abhijitpai000/product-recsys-training"><strong>Model Training (Github)</strong></a></li>
</ul>
<p><em><strong>NOTE:</strong> The web app is deployed on a free server which goes into sleep mode and takes about 10s for boot up, once loaded the bot will work as expected.</em></p>
<h2 id="architecture">Architecture</h2>
<p>The website is divided into 3 sections.
<img src="/product-recsys2.JPG" alt="product-recsys"></p>
<p>The website is divided into 3 sections.</p>
<h2 id="1-top-trending">1. Top Trending</h2>
<p><strong>Demographic Filtering</strong> - Recommends highest rated products in the dataset.</p>
<p><strong>Method</strong> - Uses <a href="https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV#calculatetop">IMDB weighted average formula</a> and recommends highest rated products.</p>
<h2 id="2-similar-products">2. Similar Products</h2>
<p><strong>Item based collaborative filtering</strong> - Takes user input of one product and recommends 5 similar products.</p>
<p><strong>Method</strong> - Computes cosine similarity between selected product and others based on historical ratings given by customers using KNN Basic algorithm.</p>
<h2 id="3-products-you-might-like">3. Products you might like</h2>
<p><strong>User based collaborative filtering</strong> - Takes user input &amp; rating of one product and recommends 3 products based on the rating given for the selected product.</p>
<p><strong>Method</strong> -   Approximates the user&rsquo;s taste by running two algorithms in the backend, first computes the most similar user who has sufficient historical data, and second, makes recommendations based on their taste.</p>
]]></content>
		</item>
		
		<item>
			<title>Text Grader</title>
			<link>https://abhijitpai000.github.io/posts/text-grader/</link>
			<pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
			
			<guid>https://abhijitpai000.github.io/posts/text-grader/</guid>
			<description>About Text Grader determines the readability of a given text using Flesch-Kincaid readability tests and provides stats about the text.
Related Links  Web app link (Heroku). Code (Github)  NOTE: The web app is deployed on a free server which goes into sleep mode and takes about 10s for boot up, once loaded the bot will work as expected.
How it Works When user inputs a text, backend performs to following.</description>
			<content type="html"><![CDATA[<h2 id="about">About</h2>
<p>Text Grader determines the readability of a given text using Flesch-Kincaid readability tests and provides stats about the text.</p>
<p><img src="/text-grader-demo2.gif" alt="Demo 2"></p>
<h2 id="related-links">Related Links</h2>
<ul>
<li><a href="http://text-grader.herokuapp.com/"><strong>Web app link (Heroku)</strong></a>.</li>
<li><a href="https://github.com/abhijitpai000/text-grader"><strong>Code (Github)</strong></a></li>
</ul>
<p><em><strong>NOTE:</strong> The web app is deployed on a free server which goes into sleep mode and takes about 10s for boot up, once loaded the bot will work as expected.</em></p>
<h2 id="how-it-works">How it Works</h2>
<p>When user inputs a text, backend performs to following.</p>
<p><strong>Test 1: The Flesch Reading Ease</strong></p>
<p>In the Flesch reading-ease test, higher scores indicate material that is easier to read; lower numbers mark passages that are more difficult to read.</p>
<p>Flesch reading-ease score (FRES):</p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bd4916e193d2f96fa3b74ee258aaa6fe242e110e" alt="alt text"></p>
<p><strong>Test 2: The Flesch Grade Level</strong></p>
<p>This test presents a score as a U.S. grade level, making it easier for teachers, parents, librarians, and others to judge the readability level of various books and texts.</p>
<p>Flesch Grade Level test score:</p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8e68f5fc959d052d1123b85758065afecc4150c3" alt="alt text"></p>
<p>Readability Tests on <a href="https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests">Wikipedia link</a></p>
]]></content>
		</item>
		
		<item>
			<title>Customer Lifetime Value</title>
			<link>https://abhijitpai000.github.io/posts/customer-lifetime-value/</link>
			<pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
			
			<guid>https://abhijitpai000.github.io/posts/customer-lifetime-value/</guid>
			<description>Overview Trained a Beta Geometric-Negative Binomial Distribution (BG/NBD) model that explains how frequently customers make purchases while they are still &amp;ldquo;alive&amp;rdquo; and how likely a customer is to churn in any given time period, using customer transactions of E-Commerce store Olist public dataset
Model Outcome
Trained Model Predicts Number of Purchases with an RMSE of 0.144 and is able to predict 99% of purchases in the test set.
Model vs Actual - Cumulative Transactions and Daily Transactions About Olist Dataset The dataset has information of 100k orders from 2016 to 2018 made at multiple marketplaces in Brazil, the orders are divided into 9 .</description>
			<content type="html"><![CDATA[<h2 id="overview">Overview</h2>
<p>Trained a Beta Geometric-Negative Binomial Distribution (BG/NBD) model that explains how frequently customers make purchases while they are still &ldquo;alive&rdquo; and how likely a customer is to churn in any given time period, using customer transactions of E-Commerce store Olist <a href="https://www.kaggle.com/olistbr/brazilian-ecommerce">public dataset</a></p>
<p><strong>Model Outcome</strong></p>
<p>Trained Model Predicts Number of Purchases with an RMSE of 0.144 and is able to predict 99% of purchases in the test set.</p>
<p><img src="/clv/output_17_0.png" alt="image.png"></p>
<p><em>Model vs Actual - Cumulative Transactions and Daily Transactions</em>
<img src="/clv/output_18_0.png" alt="image-3.png"></p>
<h2 id="about-olist-dataset">About Olist Dataset</h2>
<p>The dataset has information of 100k orders from 2016 to 2018 made at multiple marketplaces in Brazil, the orders are divided into 9 .csv files in a relational database schema.</p>
<p>For this study, I have aggregrated data using the following 3 .csv files out of the 9 in the zip file.</p>
<ul>
<li>olist_customers_dataset.csv</li>
<li>olist_orders_dataset.csv</li>
<li>olist_payments_dataset.csv</li>
</ul>
<p><strong>Source :</strong> <a href="https://www.kaggle.com/olistbr/brazilian-ecommerce">Olist Dataset</a></p>
]]></content>
		</item>
		
		<item>
			<title>Predictive Lead Scoring</title>
			<link>https://abhijitpai000.github.io/posts/predictive-lead-scoring/</link>
			<pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
			
			<guid>https://abhijitpai000.github.io/posts/predictive-lead-scoring/</guid>
			<description>Overview Predictive Lead Scoring is a method used to analyze lead behavior in historical customer data to find patterns resulting in a positive business outcome, such as a closed deal with a client. In this study, I developed a lead scoring model using the Bank Marketing dataset, which contains the outcome of clients subscribing to a term deposit or not based on a direct marketing campaign performed by a Portuguese bank.</description>
			<content type="html"><![CDATA[<h2 id="overview">Overview</h2>
<p>Predictive Lead Scoring is a method used to analyze lead behavior in historical customer data to find patterns resulting in a positive business outcome, such as a closed deal with a client. In this study, I developed a lead scoring model using the <a href="https://archive.ics.uci.edu/ml/datasets/bank+marketing">Bank Marketing</a> dataset, which contains the outcome of clients subscribing to a term deposit or not based on a direct marketing campaign performed by a Portuguese bank.</p>
<h2 id="model-design">Model Design</h2>
<p>I assumed (Losing a potential customer cost) &gt; (Sales Resource Cost) as a business objective as evaluating model outcomes, which statistically translates to developing a model that gives Low False Negatives and High True Positives, with balancing False Positives.</p>
<h2 id="model-prediction">Model Prediction</h2>
<p>To mimic a real-time model evaluation, I separated ~10,000 observation points from the dataset and trained on ~30,000 observation points. The following is the result of my trained LightGBM model on the hold-out dataset.</p>
<blockquote>
<p>75.04% of Leads predicted by the model have resulted in conversion. And, a 29.56% False Positive rate, 24.95% False Negative Rate is observed.</p>
</blockquote>
<p><em>Segmenting Leads based on Model Predictions:</em></p>
<p><img src="/lead-scoring/output_20_1.png" alt="image.png"></p>
<h2 id="data-source">Data Source</h2>
<p>I used <a href="https://archive.ics.uci.edu/ml/datasets/bank+marketing">UCI Machine Learning Repository Bank Marketing</a> dataset.</p>
]]></content>
		</item>
		
		<item>
			<title>Customer Segmentation - RFM</title>
			<link>https://abhijitpai000.github.io/posts/customer-segmentation/</link>
			<pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
			
			<guid>https://abhijitpai000.github.io/posts/customer-segmentation/</guid>
			<description>Overview Recency-Frequency-Monetary Value (RFM) is a quantitative technique used to analyze &amp;amp; group customers based on their purchase history by assigning numerical values (1 to K) for customer groups. In this study, I computed RFM for each customer based on their purchases (using definitions below), then applied the K-Means clustering algorithm, which aims to partition N-observations into K-clusters by assigning each observation a random cluster number (0 to K), based on nearest &amp;lsquo;Means&amp;rsquo;.</description>
			<content type="html"><![CDATA[<h2 id="overview">Overview</h2>
<p>Recency-Frequency-Monetary Value (RFM) is a quantitative technique used to analyze &amp; group customers based on their purchase history by assigning numerical values (1 to K) for customer groups. In this study, I computed RFM for each customer based on their purchases (using definitions below), then applied the K-Means clustering algorithm, which aims to partition N-observations into K-clusters by assigning each observation a random cluster number (0 to K), based on nearest &lsquo;Means&rsquo;.</p>
<p>Using this randomly generated cluster numbers (0 to 4) as scores, I re-structured it to a scale of 1 to 5 and assigned the customer group that is recent, frequent, and generates high monetary value a higher score.</p>
<ul>
<li><strong>Recency:</strong> Days since the last transcation.</li>
<li><strong>Frequency:</strong> Transactions Count.</li>
<li><strong>Monetary Value:</strong> Average Monetary Value Generated.</li>
</ul>
<p><em>Recency, Frequency and Monetary Value Clusters</em>
<img src="/segmentation/output_18_1.png" alt="image.png">
<img src="/segmentation/output_18_3.png" alt="image.png">
<img src="/segmentation/output_18_5.png" alt="image.png"></p>
<h2 id="data-source">Data Source</h2>
<p>I used <a href="https://www.kaggle.com/vijayuv/onlineretail">Online Retail</a> dataset from Kaggle.</p>
]]></content>
		</item>
		
		<item>
			<title>Retail Summer Sales</title>
			<link>https://abhijitpai000.github.io/posts/retail-summer-sales/</link>
			<pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
			
			<guid>https://abhijitpai000.github.io/posts/retail-summer-sales/</guid>
			<description>Understanding how well a product that is published on the E-Commerce platform Wish is going to sell using Machine Learning.
Overview In this study, I extracted 10 significant features out of 43 provided in the dataset and trained a Linear Regression model that predicts &amp;ldquo;units_sold&amp;rdquo; of products.
Evaluation Metrics used: Mean absolute error and R-Squared
Findings It is observed that out of the 10 features, products marked rating 3 and 5 have a significant positive impact on sales, followed by merchants who used ad boosts, their total rating count, discount percent on the product, with a retail price of the product having a significant negative impact.</description>
			<content type="html"><![CDATA[<p>Understanding how well a product that is published on the E-Commerce platform Wish is going to sell using Machine Learning.</p>
<h2 id="overview">Overview</h2>
<p>In this study, I extracted 10 significant features out of 43 provided in the dataset and trained a Linear Regression model that predicts &ldquo;units_sold&rdquo; of products.</p>
<p><strong>Evaluation Metrics used:</strong> Mean absolute error and R-Squared</p>
<h2 id="findings">Findings</h2>
<p>It is observed that out of the 10 features, products marked rating 3 and 5 have a significant positive impact on sales, followed by merchants who used ad boosts, their total rating count, discount percent on the product, with a retail price of the product having a significant negative impact.</p>
<p><strong>Sales Estimator Equation:</strong></p>
<p><strong>units_sold</strong> = <em>(uses_ad_boosts x 642.80) + (rating_three_count x 15.06) + (rating_five_count x 3.33) +
(merchant_rating_count x 0.003) + (product_id x -0.850) + (discount x -1.73) +
(discount_percent x -6.038) + (product_variation_size_id x -10.65) +
(retail_price x -16.418) + (badge_fast_shipping x -3173.258)</em></p>
<p><em>Note: Weights for each feature are absolute weights, may differ from relative weights obtained by transforming features to a common scale, which is depicted in the plot below</em></p>
<p><strong>Relative Weights :</strong></p>
<p><img src="/summer-sales/fw.png" alt="image.png"></p>
<h2 id="data-source">Data Source</h2>
<p>The <a href="https://www.kaggle.com/jmmvutu/summer-products-and-sales-in-ecommerce-wish">Summer Sales</a> data used contains sales data of products published on E-Commerce platform Wish.</p>
]]></content>
		</item>
		
	</channel>
</rss>
